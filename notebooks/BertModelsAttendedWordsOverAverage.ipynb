{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BertModelsAttendedWordsOverAverage.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9cee813346f44f618f039e1fe12a2476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_88fb73ff05bc4dc68f765177b05c2fd5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_679cba53a25e4595baff262eab38cefb",
              "IPY_MODEL_724df2c92d364b10866fc036095ed2ed"
            ]
          }
        },
        "88fb73ff05bc4dc68f765177b05c2fd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "679cba53a25e4595baff262eab38cefb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_06dea0c04f3a4b7caafb42c83faf1776",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 385,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 385,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c38e2aa21d240a6b719deee927712d1"
          }
        },
        "724df2c92d364b10866fc036095ed2ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6740ab057ef543cda7a9b26ee093215d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 385/385 [00:00&lt;00:00, 1.02kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bcd113ab104e485cb47f7e4bb1dc27d7"
          }
        },
        "06dea0c04f3a4b7caafb42c83faf1776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c38e2aa21d240a6b719deee927712d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6740ab057ef543cda7a9b26ee093215d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bcd113ab104e485cb47f7e4bb1dc27d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0394282f509e4c909480e75179a9a897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a95baa8425de4236af11ea46ba856516",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bc46fa4e234540b58efeef2a3e2508be",
              "IPY_MODEL_b22bf613f9d94cc0838645e2990b3af7"
            ]
          }
        },
        "a95baa8425de4236af11ea46ba856516": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc46fa4e234540b58efeef2a3e2508be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_160a19ce782e4e70a0eb77002b5af7c2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 227845,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 227845,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6327d32add694217917adf098b933f82"
          }
        },
        "b22bf613f9d94cc0838645e2990b3af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5eec61c13e794fb4bd451b19db4b5445",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 228k/228k [00:03&lt;00:00, 75.9kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c6d495768c644015b70af1a63ca68e59"
          }
        },
        "160a19ce782e4e70a0eb77002b5af7c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6327d32add694217917adf098b933f82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5eec61c13e794fb4bd451b19db4b5445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c6d495768c644015b70af1a63ca68e59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ1W3dmWHuXB"
      },
      "source": [
        "## Download dataset fine-tuned models and libraries "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_zGQHmbISLC"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_4Ddloyk8DO",
        "outputId": "46389086-5367-4382-c091-f5343c488b9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!gdown --id 1XOtSCqfzMC3_XWY8Ylw_josDAJOjMwOF"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1XOtSCqfzMC3_XWY8Ylw_josDAJOjMwOF\n",
            "To: /content/articles_scigraph_2011.json\n",
            "274MB [00:04, 63.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP1x1fMnVIgq"
      },
      "source": [
        "Choose only one model below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9oqXrkjH1Le"
      },
      "source": [
        "### Option 1: Fine-tuned SciBERT on articles clasification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqNZtguO99Us",
        "outputId": "b8c2de00-99a6-4127-f367-83db6287e4f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!gdown --id 1uKFfoh95K7lRXEwdMt7F32ivohwAENzT"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1uKFfoh95K7lRXEwdMt7F32ivohwAENzT\n",
            "To: /content/scibert10v2_scigraph0.pt\n",
            "440MB [00:07, 57.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa7sawoCQRj1"
      },
      "source": [
        "### Option 2: Fine-tuned BERT on articles clasification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqkkvurIQXWj"
      },
      "source": [
        "!gdown --id 19pNPMyguDUPOlza-B4J-NqOOdU-ZqGwl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75AFWS0JQbWK"
      },
      "source": [
        "### Option 3: Fine-tuned BioBERT 1.1 on articles clasification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5TUOSD3QbWL"
      },
      "source": [
        "!gdown --id 1waZOhC4LADr6rQx0cf3LRA4UZSj6u2uu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzVaPSqDM8EP"
      },
      "source": [
        "Download library used to fine-tune the LM on mutilabel classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIcu-vgxly0h",
        "outputId": "703d269e-79cc-4d6d-8aa1-a1c152bdb2ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!gdown --id 1LpufGkbVYTGxgAHr2TyqQimqVRte420U"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1LpufGkbVYTGxgAHr2TyqQimqVRte420U\n",
            "To: /content/BertModeling.py\n",
            "\r  0% 0.00/14.4k [00:00<?, ?B/s]\r100% 14.4k/14.4k [00:00<00:00, 15.5MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_cVGapAKIlI",
        "outputId": "a4fd6f19-fa24-4cdd-9743-e76910bbddf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "articles_scigraph_2011.json  sample_data\n",
            "BertModeling.py\t\t     scibert10v2_scigraph0.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FdMlp30eGPz"
      },
      "source": [
        "## Install and import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDAwPZI5hZ2e",
        "outputId": "928a701e-2cff-49fb-bcbc-4c6f289e81ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install 'transformers==2.8.0'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 573kB 2.8MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.7MB 13.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 28.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.18.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 34.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2.23.0)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/76/1f853a1ff319c173c638f38c34ebb389389253bf828e18fc4de52a2f4288/boto3-1.16.7-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133kB 46.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (3.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (0.17.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2.10)\n",
            "Collecting botocore<1.20.0,>=1.19.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/58/64883046f9c98d9f94cc81174d0b83e0be35b8f6c252e255b709b9024ef1/botocore-1.19.7-py2.py3-none-any.whl (6.7MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.7MB 47.4MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 10.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.7->boto3->transformers==2.8.0) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=4564a4b321cafe1b958035bcafbc235ed3cc8e9519d7d39779526e3792642b5a\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "\u001b[31mERROR: botocore 1.19.7 has requirement urllib3<1.26,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, jmespath, botocore, s3transfer, boto3, transformers\n",
            "Successfully installed boto3-1.16.7 botocore-1.19.7 jmespath-0.10.0 s3transfer-0.3.3 sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF0reHdby-YP"
      },
      "source": [
        "import sys\n",
        "\n",
        "from BertModeling import BertForMultiLabelSequenceClassification\n",
        "from BertModeling import (BertForMultiLabelSequenceClassification, BioBertForMultiLabelSequenceClassification, \n",
        "                         BioBertForMultiLabelSequenceClassification2, XLNetForMultiLabelSequenceClassification,\n",
        "                          GPT2MultiLabelClassification)\n",
        "from transformers import (WEIGHTS_NAME, BertConfig, BertForSequenceClassification, BertTokenizer, AutoTokenizer, AutoModelWithLMHead,AutoConfig,\n",
        "                                  XLMConfig, XLMForSequenceClassification, XLMTokenizer, \n",
        "                                  XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer,\n",
        "                                  RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer)\n",
        "#from bertviz.transformers_neuron_view import BertModel, BertTokenizer, BertForPreTraining, BertForSequenceClassification\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
        "                              TensorDataset)\n",
        "import csv\n",
        "import json\n",
        "import pprint"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0klcUIYtL3PR",
        "outputId": "ba999950-c8af-4cf4-fa26-c6985ee51d70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evk4z9YvMbkI"
      },
      "source": [
        "## Load the fine-tuned language models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK0EI6iEMh3K"
      },
      "source": [
        "Choose only one of the models by running the corresponding cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7DpF6rxM2d9"
      },
      "source": [
        "#### Option 1: Fine-tuned SciBERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6X4jQgKL8ZJ",
        "outputId": "9e9d14f3-4a90-4897-e30b-f6c01dbbcbd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9cee813346f44f618f039e1fe12a2476",
            "88fb73ff05bc4dc68f765177b05c2fd5",
            "679cba53a25e4595baff262eab38cefb",
            "724df2c92d364b10866fc036095ed2ed",
            "06dea0c04f3a4b7caafb42c83faf1776",
            "6c38e2aa21d240a6b719deee927712d1",
            "6740ab057ef543cda7a9b26ee093215d",
            "bcd113ab104e485cb47f7e4bb1dc27d7",
            "0394282f509e4c909480e75179a9a897",
            "a95baa8425de4236af11ea46ba856516",
            "bc46fa4e234540b58efeef2a3e2508be",
            "b22bf613f9d94cc0838645e2990b3af7",
            "160a19ce782e4e70a0eb77002b5af7c2",
            "6327d32add694217917adf098b933f82",
            "5eec61c13e794fb4bd451b19db4b5445",
            "c6d495768c644015b70af1a63ca68e59"
          ]
        }
      },
      "source": [
        "#scibert \n",
        "pretrainedModelpath = 'allenai/scibert_scivocab_uncased' \n",
        "modelpath = './scibert10v2_scigraph0.pt' #fine-tuned model\n",
        "\n",
        "config = AutoConfig.from_pretrained('allenai/scibert_scivocab_uncased', output_hidden_states=True, output_attentions=True, num_labels=22)#\n",
        "model = BertForMultiLabelSequenceClassification(config=config)\n",
        "model.load_state_dict(torch.load(modelpath))\n",
        "\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(pretrainedModelpath, do_lower_case=True, return_token_type_ids=True)\n",
        "model.eval()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9cee813346f44f618f039e1fe12a2476",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=385.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0394282f509e4c909480e75179a9a897",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=227845.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMultiLabelSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=22, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4quwVpCMm0T"
      },
      "source": [
        "### Option 2: Fine-tuned BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJD4d1tvMCXh"
      },
      "source": [
        "#Bert \n",
        "modelpath = \"./bert_scigraph0.pt\" \n",
        "\n",
        "config = BertConfig(output_hidden_states=True, output_attentions=True, num_labels=22)\n",
        "model = BertForMultiLabelSequenceClassification(config=config)\n",
        "model.load_state_dict(torch.load(modelpath))\n",
        "\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True, return_token_type_ids=True)\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCssnvX8M0aW"
      },
      "source": [
        "### Option 3: Fine-tuned BioBERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPCg78r4MCjw"
      },
      "source": [
        "#BioBert \n",
        "pretrainedModelpath = 'monologg/biobert_v1.1_pubmed'\n",
        "modelpath = \"./biobert11v2_scigraph0.pt\" #fine-tuned model\n",
        "\n",
        "config = AutoConfig.from_pretrained(pretrainedModelpath+'config.json', output_hidden_states=True, output_attentions=True, num_labels=22)#\n",
        "model = BioBertForMultiLabelSequenceClassification2(config=config)\n",
        "model.load_state_dict(torch.load(modelpath))\n",
        "model = model.bert\n",
        "\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(pretrainedModelpath, do_lower_case=True, return_token_type_ids=True)\n",
        "model.eval()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0ZyaLnYUpcb"
      },
      "source": [
        "## Word tokenizer out of subword tokenizers\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJVVM-Yp3pqE"
      },
      "source": [
        "### Extract word vocabulary from subwords\n",
        "\n",
        "The dataset is a subset of articles with a max numbero of 10 in each category\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0sl_lHNVmqM",
        "outputId": "078ab2a4-a73f-4e21-9d9c-b4b3f278251d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import re\n",
        "sc_text = []\n",
        "bert_word_counts = {} # words to freq \n",
        "bert_word_index = {} # words to index\n",
        "bert_index_word = {} # index to words\n",
        "category_articles={} # category to articles\n",
        "article_categories={} # articles to categories\n",
        "\n",
        "# JSON FILE annotated text\n",
        "with open('./articles_scigraph_2011.json') as json_file:\n",
        "    docs = json.load(json_file)\n",
        "\n",
        "    docCounter=0\n",
        "    for j,doc in enumerate(docs):\n",
        "        skip=False\n",
        "        str = doc[\"title\"]+\". \" + doc[\"abstract\"]       \n",
        "\n",
        "        #Check max of 10 articles per category        \n",
        "        for cat in doc[\"fieldcodes\"]:\n",
        "            if len(cat) == 2:                \n",
        "                if cat in category_articles:\n",
        "                    articles = category_articles[cat]\n",
        "                    if (len(articles)<10):                        \n",
        "                        articles.append(docCounter)\n",
        "                        category_articles[cat] = articles                        \n",
        "                    else:\n",
        "                        skip=True\n",
        "                else:\n",
        "                    category_articles[cat] = [docCounter]                    \n",
        "        if skip==True:\n",
        "            continue\n",
        "            \n",
        "        sc_text.append(str)\n",
        "        article_categories[docCounter] = [x for x in doc[\"fieldcodes\"] if len(x)==2]\n",
        "        docCounter+=1\n",
        "        \n",
        "        \n",
        "        #Extract word vocabulary\n",
        "        #print(str)\n",
        "        tokenized_sentence = bert_tokenizer.encode(str, add_special_tokens=False, truncation=True, max_length = 512 )\n",
        "        tokens = bert_tokenizer.convert_ids_to_tokens(tokenized_sentence) #this way the special tokens are added   \n",
        "        subword=False\n",
        "        newword=False        \n",
        "        for i,t in enumerate(tokens):            \n",
        "            if t.startswith(\"##\") == False :                  \n",
        "                if (subword == True or newword == True) :                    \n",
        "                    #add word to the dict\n",
        "                    if word in bert_word_counts:\n",
        "                        bert_word_counts[word]+=1\n",
        "                    else:\n",
        "                        bert_word_counts[word]=1                    \n",
        "                    subword = False            \n",
        "                word = t\n",
        "                newword = True\n",
        "            else:\n",
        "                subword = True\n",
        "                word = word + t[2:] #remove ##                                  \n",
        "        if j == 10000:\n",
        "            break \n",
        "       \n",
        "         \n",
        "#sort words by frequency\n",
        "sorted_voc ={k: v for k, v in sorted(bert_word_counts.items(), key=lambda item: item[1], reverse=True)}\n",
        "bert_word_index = dict(zip(sorted_voc, list(range(1, len(sorted_voc) + 1))))\n",
        "bert_index_word = {c: w for w, c in bert_word_index.items()}\n",
        "\n",
        "\n",
        "for cat, articles in {k: v for k, v in sorted(category_articles.items(), key=lambda item: item[0])}.items() :\n",
        "      print(cat,\":\",len(articles))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01 : 10\n",
            "02 : 10\n",
            "03 : 10\n",
            "04 : 10\n",
            "05 : 10\n",
            "06 : 10\n",
            "07 : 10\n",
            "08 : 10\n",
            "09 : 10\n",
            "10 : 10\n",
            "11 : 10\n",
            "12 : 10\n",
            "13 : 10\n",
            "14 : 10\n",
            "15 : 10\n",
            "16 : 10\n",
            "17 : 10\n",
            "18 : 10\n",
            "19 : 10\n",
            "20 : 10\n",
            "21 : 10\n",
            "22 : 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_oh_MKM3wHf"
      },
      "source": [
        "### Get word sequences from subword sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaimbcBM1s5G",
        "outputId": "d60bb8da-5549-487b-dee0-8f1c25fc25e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## use the wordindex to keep track of the sequence and of the start and end idx of each word.\n",
        "word_seqs = [] #according to OUR word index of whole tokens built out of word pieces tokens\n",
        "word_seqs_words = []\n",
        "starts = [] \n",
        "ends = []\n",
        "\n",
        "#BERT tokenizer representations\n",
        "subword_seqs = [] #token ids\n",
        "subword_seqs_tokens = [] #token strings\n",
        "\n",
        "for k,paper in enumerate(sc_text):            \n",
        "    tokenized_sentence = bert_tokenizer.encode(paper, add_special_tokens=False, truncation=True, max_length = 512)       \n",
        "    tokens = bert_tokenizer.convert_ids_to_tokens(tokenized_sentence)    \n",
        "    subword_seqs.append(tokenized_sentence)\n",
        "    subword_seqs_tokens.append(tokens)\n",
        "    #print(subword_seqs)\n",
        "    subword=False\n",
        "    newword=False\n",
        "    word_seq = []\n",
        "    start = []\n",
        "    end=[]\n",
        "    for i,t in enumerate(tokens):  \n",
        "        #To deal with subwords\n",
        "        if t.startswith(\"##\") == False :                  \n",
        "            if (subword == True or newword == True) :\n",
        "                #add word to the dict\n",
        "                word_seq.append(bert_word_index[word])                \n",
        "                start.append(start_idx)\n",
        "                end.append(end_idx)                \n",
        "                subword = False            \n",
        "            word = t\n",
        "            start_idx = i\n",
        "            end_idx = start_idx\n",
        "            newword = True\n",
        "        else:\n",
        "            subword = True\n",
        "            word = word + t[2:] #remove ##\n",
        "            end_idx = i\n",
        "    word_seqs.append(word_seq)\n",
        "    starts.append(start)\n",
        "    ends.append(end)\n",
        "\n",
        "    #print(tokenized_sentence)\n",
        "#     if k==1000:\n",
        "#         break;\n",
        "    \n",
        "print(len(word_seqs))\n",
        "print(len(starts))\n",
        "print(len(ends))\n",
        "print(len(subword_seqs))\n",
        "print(len(subword_seqs_tokens))\n",
        "    "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "179\n",
            "179\n",
            "179\n",
            "179\n",
            "179\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKb-Fau55Sq5"
      },
      "source": [
        "## Extract attended words above average in the last hidden states"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6yV4QYe5afK"
      },
      "source": [
        "### Option 1: Get most attended words in all articles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVHTWUP747Yh"
      },
      "source": [
        "#FOR EACH ARTICLE\n",
        "\n",
        "all_word_idx_counts={}\n",
        "all_word_idx_avg_att={}\n",
        "for l,subword_seq in enumerate(subword_seqs):\n",
        "    input_ids = torch.tensor(subword_seq).unsqueeze(0)\n",
        "    outputs = model(input_ids)\n",
        "    #get the last layer attention  \n",
        "   \n",
        "    #ITERATE OVER EACH LAYER ATTENTION HEADS \n",
        "    for i, out in enumerate(outputs[-1]):            \n",
        "        if i != 11: #We only care about the last layer\n",
        "            continue\n",
        "            \n",
        "        att = out[0] #Get attention heads of this layer (12 attention heads)\n",
        "        matrix = torch.zeros(att[0].shape) # Avg attention across 12 heads\n",
        "        for a in att: \n",
        "            matrix = matrix + a\n",
        "        matrix = matrix/12                               \n",
        "        matrix = matrix.detach().numpy()         \n",
        "        word_seq = word_seqs[l] #word sequence for this paper\n",
        "        start = starts[l] #start token idx for words\n",
        "        end = ends[l]     #end token idx for words\n",
        "                   \n",
        "        #GENERATE NEW ATTENTION MATRIX (1 step: WHOLE_WORDS X TOKENS)\n",
        "        for j,word_idx in enumerate(word_seq):\n",
        "            t_start = start[j]\n",
        "            t_end = end[j]\n",
        "            # ROWS: Average attentions of word tokens by rows         \n",
        "            if t_start == t_end:\n",
        "                attention_word_row = matrix[t_start,:]\n",
        "            else:\n",
        "                attention_word_row = np.mean(matrix[t_start:t_end+1,:], dtype=np.float64, axis=0)                                                \n",
        "            # NEW MATRIX: Stack new rows (#of rows = # of words)\n",
        "            if j == 0:\n",
        "                new_matrix_rows = attention_word_row                                \n",
        "            else:\n",
        "                new_matrix_rows=np.vstack((new_matrix_rows,attention_word_row))\n",
        "\n",
        "        #GENERATE NEW ATTENTION MATRIX (2 step: WHOLE_WORDS X WHOLE_WORDS)\n",
        "        for j,word_idx in enumerate(word_seq):\n",
        "            t_start = start[j]\n",
        "            t_end = end[j]        \n",
        "            # COLUMNS average attention of word tokens by column          \n",
        "            if t_start == t_end:\n",
        "                attention_word_col = new_matrix_rows[:,t_start]\n",
        "            else:\n",
        "                attention_word_col = np.mean(new_matrix_rows[:,t_start:t_end+1], dtype=np.float64, axis=1)                                                                \n",
        "            # NEW MATRIX: Stack new rows representing columns (#of rows = # of words)    \n",
        "            if j == 0:\n",
        "                new_matrix = attention_word_col            \n",
        "            else:\n",
        "                new_matrix=np.vstack((new_matrix,attention_word_col))\n",
        "        # Transpose the matrix to convert the rows into columns\n",
        "        new_matrix = new_matrix.T        \n",
        "        \n",
        "        avgatt = np.mean(new_matrix, dtype=np.float64)\n",
        "       \n",
        "        #IDENTIFY WORDS WITH COLUMN ATTENTION AVERAGE GREATER THAN THE MATRIX AVERAGE        \n",
        "        for word_position, row in enumerate(new_matrix.T): #Used the transpose of the attention matrix to get the columns as rows\n",
        "            if np.mean(row)>=avgatt:              \n",
        "                word_idx = word_seqs[l][word_position] #get the word idx from sequence\n",
        "                #keep track of the times the word has been attended above average\n",
        "                if word_idx in all_word_idx_counts:\n",
        "                    all_word_idx_counts[word_idx] +=1\n",
        "                else:\n",
        "                    all_word_idx_counts[word_idx] = 1\n",
        "                #keep track of the average attention\n",
        "                if word_idx in all_word_idx_avg_att:\n",
        "                    all_word_idx_avg_att[word_idx] += float(np.mean(row))/2\n",
        "                else:\n",
        "                    all_word_idx_avg_att[word_idx] = float(np.mean(row))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sKmh_JO7EV0"
      },
      "source": [
        "#### Print most attended words in the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG01DMVM7Eo0",
        "outputId": "418080f8-f30d-4ff5-e9db-cebc00b31b3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Print attended words   \n",
        "sorted_word_idx_counts={k: v for k, v in sorted(all_word_idx_counts.items(), key=lambda item: item[1], reverse=True)[:20]}    \n",
        "for word_idx in sorted_word_idx_counts:\n",
        "    print(bert_index_word[word_idx],\":\",sorted_word_idx_counts[word_idx])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ". : 1315\n",
            ", : 119\n",
            "the : 93\n",
            "surface : 32\n",
            "water : 30\n",
            "film : 27\n",
            "students : 22\n",
            "tree : 21\n",
            "social : 20\n",
            "data : 17\n",
            "adsorption : 17\n",
            "building : 17\n",
            "forest : 17\n",
            "models : 16\n",
            "knowledge : 16\n",
            "carbon : 15\n",
            "education : 15\n",
            "literature : 15\n",
            "management : 14\n",
            "species : 14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZt7WTFj6IlJ"
      },
      "source": [
        "### Option 2: Get most attended words in each research category"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjzjLPlU5_Ft"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "category_word_idx_counts={} # word_idx_count per category\n",
        "category_word_idx_avg_att={} # word_idx_avg_att per category\n",
        "\n",
        "#FOR EACH ARTICLE\n",
        "for l,subword_seq in enumerate(subword_seqs):\n",
        "    \n",
        "    word_idx_counts={} #per each article    \n",
        "    word_idx_avg_att={} #per each article    \n",
        "    input_ids = torch.tensor(subword_seq).unsqueeze(0)\n",
        "    outputs = model(input_ids)\n",
        "    \n",
        "    #ITERATE OVER EACH LAYER ATTENTION HEADS \n",
        "    for i, out in enumerate(outputs[-1]):            \n",
        "        if i != 11: #We only care about the last layer\n",
        "            continue\n",
        "            \n",
        "        att = out[0] #Get attention heads of this layer (12 attention heads)\n",
        "        matrix = torch.zeros(att[0].shape) # Avg attention across 12 heads\n",
        "        for a in att: \n",
        "            matrix = matrix + a\n",
        "        matrix = matrix/12                               \n",
        "        matrix = matrix.detach().numpy()                       \n",
        "        word_seq = word_seqs[l] #word sequence for this paper\n",
        "        start = starts[l] #start token idx for words\n",
        "        end = ends[l]     #end token idx for words\n",
        "\n",
        "        #GENERATE NEW ATTENTION MATRIX (1 step: WHOLE_WORDS X TOKENS)\n",
        "        for j,word_idx in enumerate(word_seq):\n",
        "            t_start = start[j]\n",
        "            t_end = end[j]\n",
        "            # ROWS: Average attentions of word tokens by rows         \n",
        "            if t_start == t_end:\n",
        "                attention_word_row = matrix[t_start,:]\n",
        "            else:\n",
        "                attention_word_row = np.mean(matrix[t_start:t_end+1,:], dtype=np.float64, axis=0)                                                \n",
        "            # NEW MATRIX: Stack new rows (#of rows = # of words)\n",
        "            if j == 0:\n",
        "                new_matrix_rows = attention_word_row                                \n",
        "            else:\n",
        "                new_matrix_rows=np.vstack((new_matrix_rows,attention_word_row))\n",
        "\n",
        "        #GENERATE NEW ATTENTION MATRIX (2 step: WHOLE_WORDS X WHOLE_WORDS)\n",
        "        for j,word_idx in enumerate(word_seq):\n",
        "            t_start = start[j]\n",
        "            t_end = end[j]        \n",
        "            # COLUMNS average attention of word tokens by column          \n",
        "            if t_start == t_end:\n",
        "                attention_word_col = new_matrix_rows[:,t_start]\n",
        "            else:\n",
        "                attention_word_col = np.mean(new_matrix_rows[:,t_start:t_end+1], dtype=np.float64, axis=1)                                                                \n",
        "            # NEW MATRIX: Stack new rows representing columns (#of rows = # of words)    \n",
        "            if j == 0:\n",
        "                new_matrix = attention_word_col            \n",
        "            else:\n",
        "                new_matrix=np.vstack((new_matrix,attention_word_col))\n",
        "        # Transpose the matrix to convert the rows into columns\n",
        "        new_matrix = new_matrix.T        \n",
        "        \n",
        "        avgatt = np.mean(new_matrix, dtype=np.float64)\n",
        "        \n",
        "        #IDENTIFY WORDS WITH COLUMN ATTENTION AVERAGE GREATER THAN THE MATRIX AVERAGE        \n",
        "        for word_position, row in enumerate(new_matrix.T): #Used the transpose of the attention matrix to get the columns as rows\n",
        "            if np.mean(row)>=avgatt:              \n",
        "                word_idx = word_seqs[l][word_position] #get the word idx from sequence\n",
        "                if word_idx in word_idx_counts:\n",
        "                    word_idx_counts[word_idx] +=1\n",
        "                else:\n",
        "                    word_idx_counts[word_idx] = 1\n",
        "                #keep track of the average attention\n",
        "                if word_idx in word_idx_avg_att:\n",
        "                    word_idx_avg_att[word_idx] += float(np.mean(row))/2\n",
        "                else:\n",
        "                    word_idx_avg_att[word_idx] = float(np.mean(row))\n",
        "        \n",
        "    #get article categories\n",
        "    cats = article_categories[l]\n",
        "    for cat in cats:\n",
        "        if cat in category_word_idx_counts:            \n",
        "            category_word_idx_counts[cat] = dict(Counter(category_word_idx_counts[cat])+Counter(word_idx_counts)) #merge the two dictionaries and add the values of same keys\n",
        "        else:\n",
        "            category_word_idx_counts[cat] = word_idx_counts\n",
        "        #save the average attention\n",
        "        if cat in category_word_idx_avg_att:            \n",
        "            #merge the two dictionaries and average the values of same keys\n",
        "            A=category_word_idx_avg_att[cat]\n",
        "            B=word_idx_avg_att\n",
        "            sums = dict(Counter(A) + Counter(B)) \n",
        "            category_word_idx_avg_att[cat] = means = {k: sums[k] / float((k in A) + (k in B)) for k in sums}\n",
        "        else:\n",
        "            category_word_idx_avg_att[cat] = word_idx_avg_att"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWu1G0yJ6lJ5"
      },
      "source": [
        "#### Print most attended words in research categories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOau0w7i6vfL",
        "outputId": "05e6a0e5-616f-418b-af32-f3e8249ca16c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "first_level_categories = {'01':'Mathematical Sciences','02':'Physical Sciences','03':'Chemical Sciences',\n",
        "                          '04':'Earth Sciences','05':'Environmental Sciences','06':'Biological Sciences',\n",
        "                          '07':'Agricultural and Veterinary Sciences','08':'Information and Computing Sciences',\n",
        "                          '09':'Engineering','10':'Technology','11':'Medical and Health Sciences',\n",
        "                          '12':'Built Environment and Design','13':'Education','14':'Economics',\n",
        "                          '15':'Commerce, Management, Tourism and Services','16':'Studies in Human Society',\n",
        "                          '17':'Psychology and Cognitive Sciences','18':'Law and Legal Studies',\n",
        "                          '19':'Studies in Creative Arts and Writing','20':'Language, Communication and Culture',\n",
        "                          '21':'History and Archaeology','22':'Philosophy and Religious Studies'}\n",
        "\n",
        "#print top 20\n",
        "for cat, word_idx_counts_cat in category_word_idx_counts.items():       \n",
        "    sorted_word_idx_counts_cat={k: v for k, v in sorted(word_idx_counts_cat.items(), key=lambda item: item[1], reverse=True)[:20]}        \n",
        "    for word_idx in sorted_word_idx_counts_cat:\n",
        "        print(first_level_categories[cat],\";\",bert_index_word[word_idx],\";\",sorted_word_idx_counts_cat[word_idx])       "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Medical and Health Sciences ; . ; 92\n",
            "Medical and Health Sciences ; , ; 21\n",
            "Medical and Health Sciences ; the ; 12\n",
            "Medical and Health Sciences ; models ; 12\n",
            "Medical and Health Sciences ; cardiovascular ; 8\n",
            "Medical and Health Sciences ; channels ; 6\n",
            "Medical and Health Sciences ; blood ; 5\n",
            "Medical and Health Sciences ; men ; 5\n",
            "Medical and Health Sciences ; women ; 5\n",
            "Medical and Health Sciences ; patient ; 4\n",
            "Medical and Health Sciences ; data ; 4\n",
            "Medical and Health Sciences ; eeg ; 4\n",
            "Medical and Health Sciences ; flow ; 4\n",
            "Medical and Health Sciences ; training ; 4\n",
            "Medical and Health Sciences ; injury ; 4\n",
            "Medical and Health Sciences ; fitness ; 4\n",
            "Medical and Health Sciences ; activity ; 4\n",
            "Medical and Health Sciences ; kv ; 4\n",
            "Medical and Health Sciences ; patients ; 3\n",
            "Medical and Health Sciences ; medication ; 3\n",
            "Engineering ; . ; 101\n",
            "Engineering ; water ; 8\n",
            "Engineering ; surface ; 5\n",
            "Engineering ; nickel ; 5\n",
            "Engineering ; devices ; 5\n",
            "Engineering ; wetland ; 4\n",
            "Engineering ; wind ; 4\n",
            "Engineering ; mechanical ; 4\n",
            "Engineering ; endoscopic ; 4\n",
            "Engineering ; flexible ; 4\n",
            "Engineering ; , ; 4\n",
            "Engineering ; equation ; 4\n",
            "Engineering ; herbicides ; 3\n",
            "Engineering ; turbine ; 3\n",
            "Engineering ; ray ; 3\n",
            "Engineering ; electron ; 3\n",
            "Engineering ; coatings ; 3\n",
            "Engineering ; carbon ; 3\n",
            "Engineering ; innovation ; 3\n",
            "Engineering ; surgical ; 3\n",
            "Chemical Sciences ; . ; 46\n",
            "Chemical Sciences ; surface ; 15\n",
            "Chemical Sciences ; carbon ; 9\n",
            "Chemical Sciences ; adsorption ; 9\n",
            "Chemical Sciences ; water ; 6\n",
            "Chemical Sciences ; transformation ; 6\n",
            "Chemical Sciences ; the ; 6\n",
            "Chemical Sciences ; nickel ; 5\n",
            "Chemical Sciences ; functional ; 5\n",
            "Chemical Sciences ; ray ; 4\n",
            "Chemical Sciences ; energy ; 4\n",
            "Chemical Sciences ; , ; 4\n",
            "Chemical Sciences ; cu ; 4\n",
            "Chemical Sciences ; hydrogen ; 4\n",
            "Chemical Sciences ; metal ; 3\n",
            "Chemical Sciences ; diffraction ; 3\n",
            "Chemical Sciences ; x ; 3\n",
            "Chemical Sciences ; properties ; 3\n",
            "Chemical Sciences ; area ; 3\n",
            "Chemical Sciences ; capacity ; 3\n",
            "Psychology and Cognitive Sciences ; . ; 61\n",
            "Psychology and Cognitive Sciences ; exercise ; 9\n",
            "Psychology and Cognitive Sciences ; staff ; 8\n",
            "Psychology and Cognitive Sciences ; agents ; 5\n",
            "Psychology and Cognitive Sciences ; chemical ; 4\n",
            "Psychology and Cognitive Sciences ; prison ; 4\n",
            "Psychology and Cognitive Sciences ; action ; 3\n",
            "Psychology and Cognitive Sciences ; informational ; 3\n",
            "Psychology and Cognitive Sciences ; , ; 3\n",
            "Psychology and Cognitive Sciences ; cognitive ; 3\n",
            "Psychology and Cognitive Sciences ; problems ; 3\n",
            "Psychology and Cognitive Sciences ; coordination ; 2\n",
            "Psychology and Cognitive Sciences ; embodied ; 2\n",
            "Psychology and Cognitive Sciences ; perception ; 2\n",
            "Psychology and Cognitive Sciences ; organization ; 2\n",
            "Psychology and Cognitive Sciences ; self ; 2\n",
            "Psychology and Cognitive Sciences ; systems ; 2\n",
            "Psychology and Cognitive Sciences ; bee ; 2\n",
            "Psychology and Cognitive Sciences ; aggression ; 2\n",
            "Psychology and Cognitive Sciences ; housing ; 2\n",
            "Mathematical Sciences ; . ; 84\n",
            "Mathematical Sciences ; , ; 12\n",
            "Mathematical Sciences ; the ; 8\n",
            "Mathematical Sciences ; control ; 7\n",
            "Mathematical Sciences ; dynamics ; 3\n",
            "Mathematical Sciences ; models ; 3\n",
            "Mathematical Sciences ; growth ; 3\n",
            "Mathematical Sciences ; uncertain ; 3\n",
            "Mathematical Sciences ; nonlinear ; 3\n",
            "Mathematical Sciences ; statistical ; 2\n",
            "Mathematical Sciences ; data ; 2\n",
            "Mathematical Sciences ; quantitative ; 2\n",
            "Mathematical Sciences ; algebra ; 2\n",
            "Mathematical Sciences ; group ; 2\n",
            "Mathematical Sciences ; relaxation ; 2\n",
            "Mathematical Sciences ; dynamic ; 2\n",
            "Mathematical Sciences ; evolution ; 2\n",
            "Mathematical Sciences ; network ; 2\n",
            "Mathematical Sciences ; logics ; 2\n",
            "Mathematical Sciences ; costs ; 2\n",
            "Earth Sciences ; . ; 64\n",
            "Earth Sciences ; surface ; 9\n",
            "Earth Sciences ; water ; 8\n",
            "Earth Sciences ; runoff ; 7\n",
            "Earth Sciences ; assimilation ; 7\n",
            "Earth Sciences ; precipitation ; 7\n",
            "Earth Sciences ; sea ; 6\n",
            "Earth Sciences ; data ; 6\n",
            "Earth Sciences ; cold ; 6\n",
            "Earth Sciences ; earthquakes ; 6\n",
            "Earth Sciences ; forcing ; 5\n",
            "Earth Sciences ; motion ; 5\n",
            "Earth Sciences ; natural ; 5\n",
            "Earth Sciences ; ocean ; 4\n",
            "Earth Sciences ; temperature ; 4\n",
            "Earth Sciences ; asian ; 4\n",
            "Earth Sciences ; geochemical ; 4\n",
            "Earth Sciences ; rocks ; 4\n",
            "Earth Sciences ; age ; 4\n",
            "Earth Sciences ; simulated ; 4\n",
            "Biological Sciences ; . ; 80\n",
            "Biological Sciences ; protein ; 10\n",
            "Biological Sciences ; methylation ; 8\n",
            "Biological Sciences ; dna ; 7\n",
            "Biological Sciences ; autophagy ; 7\n",
            "Biological Sciences ; proteins ; 7\n",
            "Biological Sciences ; gene ; 5\n",
            "Biological Sciences ; cell ; 5\n",
            "Biological Sciences ; apoptosis ; 5\n",
            "Biological Sciences ; expression ; 4\n",
            "Biological Sciences ; mitochondrial ; 4\n",
            "Biological Sciences ; chromatin ; 4\n",
            "Biological Sciences ; mitochondria ; 4\n",
            "Biological Sciences ; reprogramming ; 3\n",
            "Biological Sciences ; germ ; 3\n",
            "Biological Sciences ; sperm ; 3\n",
            "Biological Sciences ; environmental ; 3\n",
            "Biological Sciences ; stress ; 3\n",
            "Biological Sciences ; plants ; 3\n",
            "Biological Sciences ; species ; 3\n",
            "Technology ; . ; 40\n",
            "Technology ; , ; 20\n",
            "Technology ; the ; 16\n",
            "Technology ; protection ; 10\n",
            "Technology ; network ; 8\n",
            "Technology ; streaming ; 7\n",
            "Technology ; nickel ; 5\n",
            "Technology ; link ; 5\n",
            "Technology ; reliability ; 5\n",
            "Technology ; wireless ; 5\n",
            "Technology ; feedback ; 5\n",
            "Technology ; video ; 4\n",
            "Technology ; quality ; 4\n",
            "Technology ; services ; 4\n",
            "Technology ; backup ; 4\n",
            "Technology ; monitoring ; 4\n",
            "Technology ; tissue ; 4\n",
            "Technology ; carbon ; 3\n",
            "Technology ; service ; 3\n",
            "Technology ; hybrid ; 3\n",
            "Economics ; . ; 69\n",
            "Economics ; tax ; 12\n",
            "Economics ; weather ; 10\n",
            "Economics ; political ; 7\n",
            "Economics ; design ; 7\n",
            "Economics ; , ; 6\n",
            "Economics ; uncertainty ; 6\n",
            "Economics ; industrial ; 5\n",
            "Economics ; diagnostic ; 4\n",
            "Economics ; the ; 4\n",
            "Economics ; trade ; 4\n",
            "Economics ; government ; 4\n",
            "Economics ; private ; 4\n",
            "Economics ; forecasts ; 4\n",
            "Economics ; social ; 4\n",
            "Economics ; individual ; 4\n",
            "Economics ; innovation ; 4\n",
            "Economics ; test ; 3\n",
            "Economics ; rights ; 3\n",
            "Economics ; power ; 3\n",
            "Physical Sciences ; . ; 47\n",
            "Physical Sciences ; , ; 14\n",
            "Physical Sciences ; the ; 14\n",
            "Physical Sciences ; discharge ; 8\n",
            "Physical Sciences ; electrode ; 7\n",
            "Physical Sciences ; atoms ; 5\n",
            "Physical Sciences ; solid ; 5\n",
            "Physical Sciences ; particles ; 4\n",
            "Physical Sciences ; particle ; 4\n",
            "Physical Sciences ; frequency ; 4\n",
            "Physical Sciences ; plasma ; 4\n",
            "Physical Sciences ; cell ; 4\n",
            "Physical Sciences ; solutions ; 3\n",
            "Physical Sciences ; ) ; 3\n",
            "Physical Sciences ; invariant ; 3\n",
            "Physical Sciences ; measurements ; 3\n",
            "Physical Sciences ; wave ; 3\n",
            "Physical Sciences ; electron ; 3\n",
            "Physical Sciences ; discharges ; 3\n",
            "Physical Sciences ; fly ; 3\n",
            "Information and Computing Sciences ; . ; 59\n",
            "Information and Computing Sciences ; control ; 9\n",
            "Information and Computing Sciences ; water ; 6\n",
            "Information and Computing Sciences ; neural ; 4\n",
            "Information and Computing Sciences ; estimation ; 4\n",
            "Information and Computing Sciences ; traffic ; 4\n",
            "Information and Computing Sciences ; coordination ; 4\n",
            "Information and Computing Sciences ; wave ; 4\n",
            "Information and Computing Sciences ; problems ; 4\n",
            "Information and Computing Sciences ; vehicles ; 3\n",
            "Information and Computing Sciences ; uncertain ; 3\n",
            "Information and Computing Sciences ; nonlinear ; 3\n",
            "Information and Computing Sciences ; display ; 3\n",
            "Information and Computing Sciences ; ann ; 3\n",
            "Information and Computing Sciences ; computational ; 3\n",
            "Information and Computing Sciences ; search ; 3\n",
            "Information and Computing Sciences ; speech ; 3\n",
            "Information and Computing Sciences ; linguistic ; 3\n",
            "Information and Computing Sciences ; reconstruction ; 2\n",
            "Information and Computing Sciences ; images ; 2\n",
            "Studies in Human Society ; . ; 44\n",
            "Studies in Human Society ; europe ; 6\n",
            "Studies in Human Society ; racial ; 6\n",
            "Studies in Human Society ; collaborative ; 5\n",
            "Studies in Human Society ; community ; 4\n",
            "Studies in Human Society ; forest ; 4\n",
            "Studies in Human Society ; management ; 4\n",
            "Studies in Human Society ; processes ; 4\n",
            "Studies in Human Society ; security ; 4\n",
            "Studies in Human Society ; diversity ; 4\n",
            "Studies in Human Society ; spatial ; 4\n",
            "Studies in Human Society ; disposal ; 4\n",
            "Studies in Human Society ; campaign ; 4\n",
            "Studies in Human Society ; negative ; 3\n",
            "Studies in Human Society ; boundary ; 3\n",
            "Studies in Human Society ; the ; 3\n",
            "Studies in Human Society ; defence ; 3\n",
            "Studies in Human Society ; political ; 3\n",
            "Studies in Human Society ; waste ; 3\n",
            "Studies in Human Society ; elections ; 3\n",
            "Language, Communication and Culture ; . ; 46\n",
            "Language, Communication and Culture ; fashion ; 13\n",
            "Language, Communication and Culture ; culture ; 10\n",
            "Language, Communication and Culture ; language ; 10\n",
            "Language, Communication and Culture ; literature ; 9\n",
            "Language, Communication and Culture ; textual ; 8\n",
            "Language, Communication and Culture ; china ; 6\n",
            "Language, Communication and Culture ; chinese ; 6\n",
            "Language, Communication and Culture ; speech ; 4\n",
            "Language, Communication and Culture ; test ; 4\n",
            "Language, Communication and Culture ; semantic ; 4\n",
            "Language, Communication and Culture ; song ; 3\n",
            "Language, Communication and Culture ; cultural ; 3\n",
            "Language, Communication and Culture ; development ; 3\n",
            "Language, Communication and Culture ; age ; 3\n",
            "Language, Communication and Culture ; corpus ; 3\n",
            "Language, Communication and Culture ; authors ; 2\n",
            "Language, Communication and Culture ; problematic ; 2\n",
            "Language, Communication and Culture ; object ; 2\n",
            "Language, Communication and Culture ; history ; 2\n",
            "Environmental Sciences ; . ; 81\n",
            "Environmental Sciences ; soil ; 8\n",
            "Environmental Sciences ; adsorption ; 7\n",
            "Environmental Sciences ; grassland ; 6\n",
            "Environmental Sciences ; species ; 6\n",
            "Environmental Sciences ; tree ; 5\n",
            "Environmental Sciences ; soils ; 4\n",
            "Environmental Sciences ; grain ; 4\n",
            "Environmental Sciences ; accumulation ; 4\n",
            "Environmental Sciences ; forest ; 4\n",
            "Environmental Sciences ; biochar ; 4\n",
            "Environmental Sciences ; ecological ; 3\n",
            "Environmental Sciences ; , ; 3\n",
            "Environmental Sciences ; carbon ; 3\n",
            "Environmental Sciences ; green ; 3\n",
            "Environmental Sciences ; organic ; 3\n",
            "Environmental Sciences ; worms ; 3\n",
            "Environmental Sciences ; phosphorus ; 3\n",
            "Environmental Sciences ; adsorbed ; 3\n",
            "Environmental Sciences ; p ; 3\n",
            "Agricultural and Veterinary Sciences ; . ; 68\n",
            "Agricultural and Veterinary Sciences ; tree ; 16\n",
            "Agricultural and Veterinary Sciences ; animal ; 8\n",
            "Agricultural and Veterinary Sciences ; forest ; 7\n",
            "Agricultural and Veterinary Sciences ; buffalo ; 6\n",
            "Agricultural and Veterinary Sciences ; trees ; 4\n",
            "Agricultural and Veterinary Sciences ; biomedical ; 4\n",
            "Agricultural and Veterinary Sciences ; domestic ; 4\n",
            "Agricultural and Veterinary Sciences ; sheep ; 3\n",
            "Agricultural and Veterinary Sciences ; resistance ; 3\n",
            "Agricultural and Veterinary Sciences ; health ; 3\n",
            "Agricultural and Veterinary Sciences ; animals ; 3\n",
            "Agricultural and Veterinary Sciences ; carbon ; 2\n",
            "Agricultural and Veterinary Sciences ; ethanol ; 2\n",
            "Agricultural and Veterinary Sciences ; sorghum ; 2\n",
            "Agricultural and Veterinary Sciences ; genotypes ; 2\n",
            "Agricultural and Veterinary Sciences ; sugar ; 2\n",
            "Agricultural and Veterinary Sciences ; assay ; 2\n",
            "Agricultural and Veterinary Sciences ; goat ; 2\n",
            "Agricultural and Veterinary Sciences ; pig ; 2\n",
            "History and Archaeology ; . ; 85\n",
            "History and Archaeology ; europe ; 6\n",
            "History and Archaeology ; cultural ; 6\n",
            "History and Archaeology ; particle ; 5\n",
            "History and Archaeology ; photographs ; 5\n",
            "History and Archaeology ; archaeological ; 5\n",
            "History and Archaeology ; patients ; 4\n",
            "History and Archaeology ; security ; 4\n",
            "History and Archaeology ; history ; 4\n",
            "History and Archaeology ; procedures ; 3\n",
            "History and Archaeology ; defence ; 3\n",
            "History and Archaeology ; practices ; 3\n",
            "History and Archaeology ; archaeology ; 3\n",
            "History and Archaeology ; steel ; 3\n",
            "History and Archaeology ; song ; 3\n",
            "History and Archaeology ; peopling ; 3\n",
            "History and Archaeology ; gender ; 2\n",
            "History and Archaeology ; intervention ; 2\n",
            "History and Archaeology ; regression ; 2\n",
            "History and Archaeology ; asia ; 2\n",
            "Education ; . ; 53\n",
            "Education ; students ; 22\n",
            "Education ; knowledge ; 14\n",
            "Education ; education ; 14\n",
            "Education ; mathematics ; 12\n",
            "Education ; school ; 10\n",
            "Education ; curriculum ; 9\n",
            "Education ; teachers ; 9\n",
            "Education ; training ; 9\n",
            "Education ; teacher ; 6\n",
            "Education ; teaching ; 6\n",
            "Education ; university ; 5\n",
            "Education ; attitudes ; 5\n",
            "Education ; medical ; 5\n",
            "Education ; higher ; 5\n",
            "Education ; classroom ; 4\n",
            "Education ; reading ; 4\n",
            "Education ; learning ; 4\n",
            "Education ; high ; 4\n",
            "Education ; collaborative ; 4\n",
            "Law and Legal Studies ; . ; 41\n",
            "Law and Legal Studies ; legal ; 8\n",
            "Law and Legal Studies ; liability ; 6\n",
            "Law and Legal Studies ; investments ; 5\n",
            "Law and Legal Studies ; national ; 5\n",
            "Law and Legal Studies ; convention ; 5\n",
            "Law and Legal Studies ; rule ; 4\n",
            "Law and Legal Studies ; crown ; 3\n",
            "Law and Legal Studies ; modern ; 3\n",
            "Law and Legal Studies ; , ; 3\n",
            "Law and Legal Studies ; law ; 3\n",
            "Law and Legal Studies ; social ; 3\n",
            "Law and Legal Studies ; animal ; 3\n",
            "Law and Legal Studies ; international ; 3\n",
            "Law and Legal Studies ; precipitate ; 3\n",
            "Law and Legal Studies ; forest ; 2\n",
            "Law and Legal Studies ; corporate ; 2\n",
            "Law and Legal Studies ; multinational ; 2\n",
            "Law and Legal Studies ; corporations ; 2\n",
            "Law and Legal Studies ; the ; 2\n",
            "Commerce, Management, Tourism and Services ; . ; 43\n",
            "Commerce, Management, Tourism and Services ; , ; 15\n",
            "Commerce, Management, Tourism and Services ; the ; 10\n",
            "Commerce, Management, Tourism and Services ; firms ; 9\n",
            "Commerce, Management, Tourism and Services ; corporate ; 7\n",
            "Commerce, Management, Tourism and Services ; management ; 5\n",
            "Commerce, Management, Tourism and Services ; governance ; 5\n",
            "Commerce, Management, Tourism and Services ; ownership ; 5\n",
            "Commerce, Management, Tourism and Services ; events ; 5\n",
            "Commerce, Management, Tourism and Services ; industrial ; 5\n",
            "Commerce, Management, Tourism and Services ; accounts ; 5\n",
            "Commerce, Management, Tourism and Services ; account ; 5\n",
            "Commerce, Management, Tourism and Services ; firm ; 4\n",
            "Commerce, Management, Tourism and Services ; market ; 4\n",
            "Commerce, Management, Tourism and Services ; innovation ; 4\n",
            "Commerce, Management, Tourism and Services ; information ; 3\n",
            "Commerce, Management, Tourism and Services ; public ; 3\n",
            "Commerce, Management, Tourism and Services ; social ; 3\n",
            "Commerce, Management, Tourism and Services ; programs ; 3\n",
            "Commerce, Management, Tourism and Services ; individual ; 3\n",
            "Philosophy and Religious Studies ; . ; 60\n",
            "Philosophy and Religious Studies ; justice ; 6\n",
            "Philosophy and Religious Studies ; catholic ; 6\n",
            "Philosophy and Religious Studies ; , ; 5\n",
            "Philosophy and Religious Studies ; ethics ; 5\n",
            "Philosophy and Religious Studies ; ethical ; 5\n",
            "Philosophy and Religious Studies ; church ; 4\n",
            "Philosophy and Religious Studies ; moral ; 4\n",
            "Philosophy and Religious Studies ; social ; 4\n",
            "Philosophy and Religious Studies ; chemical ; 4\n",
            "Philosophy and Religious Studies ; nuclear ; 4\n",
            "Philosophy and Religious Studies ; power ; 4\n",
            "Philosophy and Religious Studies ; science ; 3\n",
            "Philosophy and Religious Studies ; roman ; 3\n",
            "Philosophy and Religious Studies ; self ; 3\n",
            "Philosophy and Religious Studies ; the ; 2\n",
            "Philosophy and Religious Studies ; interpretations ; 2\n",
            "Philosophy and Religious Studies ; institutional ; 2\n",
            "Philosophy and Religious Studies ; arguments ; 2\n",
            "Philosophy and Religious Studies ; account ; 2\n",
            "Built Environment and Design ; . ; 39\n",
            "Built Environment and Design ; building ; 15\n",
            "Built Environment and Design ; emotion ; 10\n",
            "Built Environment and Design ; agents ; 6\n",
            "Built Environment and Design ; architectural ; 6\n",
            "Built Environment and Design ; energy ; 6\n",
            "Built Environment and Design ; space ; 5\n",
            "Built Environment and Design ; action ; 4\n",
            "Built Environment and Design ; house ; 4\n",
            "Built Environment and Design ; agent ; 3\n",
            "Built Environment and Design ; buildings ; 3\n",
            "Built Environment and Design ; human ; 3\n",
            "Built Environment and Design ; construction ; 2\n",
            "Built Environment and Design ; autonomous ; 2\n",
            "Built Environment and Design ; artificial ; 2\n",
            "Built Environment and Design ; art ; 2\n",
            "Built Environment and Design ; architecture ; 2\n",
            "Built Environment and Design ; environments ; 2\n",
            "Built Environment and Design ; century ; 2\n",
            "Built Environment and Design ; dynamic ; 2\n",
            "Studies in Creative Arts and Writing ; . ; 48\n",
            "Studies in Creative Arts and Writing ; film ; 27\n",
            "Studies in Creative Arts and Writing ; the ; 5\n",
            "Studies in Creative Arts and Writing ; , ; 4\n",
            "Studies in Creative Arts and Writing ; films ; 4\n",
            "Studies in Creative Arts and Writing ; examinations ; 4\n",
            "Studies in Creative Arts and Writing ; foraging ; 4\n",
            "Studies in Creative Arts and Writing ; vortices ; 3\n",
            "Studies in Creative Arts and Writing ; examination ; 3\n",
            "Studies in Creative Arts and Writing ; viscoelastic ; 2\n",
            "Studies in Creative Arts and Writing ; equation ; 2\n",
            "Studies in Creative Arts and Writing ; media ; 2\n",
            "Studies in Creative Arts and Writing ; literature ; 2\n",
            "Studies in Creative Arts and Writing ; negative ; 2\n",
            "Studies in Creative Arts and Writing ; evolution ; 2\n",
            "Studies in Creative Arts and Writing ; equations ; 2\n",
            "Studies in Creative Arts and Writing ; gradient ; 2\n",
            "Studies in Creative Arts and Writing ; dynamics ; 2\n",
            "Studies in Creative Arts and Writing ; structure ; 2\n",
            "Studies in Creative Arts and Writing ; objects ; 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb0RRBVY9LEb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}